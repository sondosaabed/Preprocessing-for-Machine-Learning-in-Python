{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping missing data\n",
    "\n",
    "Now that you've explored the volunteer dataset and understand its structure and contents, it's time to begin dropping missing values.\n",
    "\n",
    "In this exercise, you'll drop both columns and rows to create a subset of the volunteer dataset.\n",
    "\n",
    "    Drop the Latitude and Longitude columns from volunteer, storing as volunteer_cols.\n",
    "    Subset volunteer_cols by dropping rows containing missing values in the category_desc, and store in a new variable called volunteer_subset.\n",
    "    Take a look at the .shape attribute of volunteer_subset, to verify it worked correctly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the Latitude and Longitude columns from volunteer\n",
    "volunteer_cols = volunteer.drop(columns=['Latitude','Longitude'])\n",
    "\n",
    "# Drop rows with missing category_desc values from volunteer_cols\n",
    "volunteer_subset = volunteer_cols.dropna(subset=['category_desc'])\n",
    "\n",
    "# Print out the shape of the subset\n",
    "print(volunteer_subset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting a column type\n",
    "\n",
    "If you take a look at the volunteer dataset types, you'll see that the column hits is type object. But, if you actually look at the column, you'll see that it consists of integers. Let's convert that column to type int.\n",
    "\n",
    "    Take a look at the .head() of the hits column.\n",
    "    Convert the hits column to type int.\n",
    "    Take a look at the .dtypes of the dataset again, and notice that the column type has changed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the head of the hits column\n",
    "print(volunteer[\"hits\"].head())\n",
    "\n",
    "# Convert the hits column to type int\n",
    "volunteer[\"hits\"] = volunteer[\"hits\"].astype(int)\n",
    "\n",
    "# Look at the dtypes of the dataset\n",
    "print(volunteer.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified sampling\n",
    "\n",
    "You now know that the distribution of class labels in the category_desc column of the volunteer dataset is uneven. If you wanted to train a model to predict category_desc, you'll need to ensure that the model is trained on a sample of data that is representative of the entire dataset. Stratified sampling is a way to achieve this!\n",
    "\n",
    "    Create a DataFrame of features, X, with all of the columns except category_desc.\n",
    "    Create a DataFrame of labels, y from the category_desc column.\n",
    "    Split X and y into training and test sets, ensuring that the class distribution in the labels is the same in both sets\n",
    "    Print the labels and counts in y_train using .value_counts().\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with all columns except category_desc\n",
    "X = volunteer.drop('category_desc', axis=1)\n",
    "\n",
    "# Create a category_desc labels dataset\n",
    "y = volunteer[['category_desc']]\n",
    "\n",
    "# Use stratified sampling to split up the dataset according to the y dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n",
    "\n",
    "# Print the category_desc counts from y_train\n",
    "print(y_train['category_desc'].value_counts())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
